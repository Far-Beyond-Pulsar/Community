# Pulsar Engine LLM & Tooling Content Policy

## Purpose

This document defines Pulsar Engine’s stance on the use of Large Language Models (LLMs), AI-assisted tools, and other code-generation or productivity tools.

The goal of this policy is to **explicitly protect contributors and users** from harassment, gatekeeping, or personal attacks based solely on the tools they use to write code.

This policy is a community standard, not a license restriction.

---

## Core Position

**The Pulsar community is tool-agnostic.**

Using LLMs, AI-assisted editors, code generators, linters, refactoring tools, or any other automation is:

* Allowed
* Accepted
* Not grounds for criticism, dismissal, or hostility

No contributor or user should feel attacked, shamed, or delegitimized for using AI-assisted tools.

---

## Code Is Evaluated on Quality, Not Origin

All contributions and code discussions in Pulsar are evaluated based on:

* Correctness
* Clarity
* Maintainability
* Performance characteristics
* Alignment with project goals

**How the code was written is irrelevant.**

If code meets reasonable quality standards, it shall be treated the same as any other code—regardless of whether it was written:

* By hand
* With IDE assistance
* With refactoring tools
* With LLMs or AI copilots

Conversely, low-quality code may be critiqued regardless of origin, but critiques must remain technical and constructive.

---

## Prohibited Behavior

The following behaviors are not acceptable within Pulsar spaces (issues, pull requests, discussions, chat, or reviews):

* Attacking or dismissing someone for using AI or LLMs
* Accusing contributors of incompetence or dishonesty due to AI usage
* Demanding disclosure of whether code was AI-generated
* Treating AI-assisted code as inherently inferior
* Derailing technical discussions into arguments about the legitimacy of AI tools

Disagreement about tooling philosophies is allowed. Personal attacks are not.

---

## No Disclosure Requirement

Contributors are **not required** to disclose whether code was written with the assistance of an LLM or any other tool.

Voluntary disclosure is welcome if relevant to discussion, but it must never be pressured or demanded.

---

## Constructive Criticism Guidelines

When reviewing or discussing code:

* Focus on the code itself
* Provide actionable feedback
* Avoid speculation about how the code was produced
* Avoid moral or ideological arguments about tools

Statements such as “this looks AI-generated” are not constructive feedback and should be avoided.

---

## Rationale

Pulsar values:

* Engineering outcomes over personal workflows
* Results over aesthetics
* Collaboration over ideology

Modern software development already relies heavily on automation. LLMs are a continuation of this trend, not an exception.

Rejecting contributors based on tools used harms inclusivity, discourages participation, and provides no technical benefit.

---

## Enforcement

Project maintainers will enforce this policy as part of the broader Community Policy.

If someone is targeted, harassed, or attacked for their choice of tools, maintainers may:

* Intervene in the discussion
* Request changes in behavior
* Remove hostile comments
* Apply moderation actions if necessary

The goal of enforcement is to protect contributors and maintain a healthy, productive community.

---

## Closing Statement

Pulsar Engine is about building great software.

If you write reasonable-quality code, engage in good faith, and respect others, you belong here—regardless of the tools you use to get there.
